{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Runner-colab.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol_x2cvWshvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import time\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9HCrTdQswWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNNScalarForm(nn.Module):\n",
        "\n",
        "    def __init__(self, check_with_pytorch=False):\n",
        "        super(CNNScalarForm, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "        self.fc1 = nn.Linear(12 * 12 * 20, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "        self.check_with_pytorch = check_with_pytorch\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.check_with_pytorch:\n",
        "            return self._forward_with_cmp(x)\n",
        "\n",
        "        return self._forward(x)\n",
        "\n",
        "\n",
        "    def _forward(self, x):\n",
        "        z_conv = self._conv(x, self.conv1.weight, self.conv1.bias)\n",
        "        z_pool = self._max_pool_kernel2(z_conv)\n",
        "\n",
        "        z_reshape = self._reshape(z_pool)\n",
        "\n",
        "        z_fc1 = self._fc(z_reshape, self.fc1.weight, self.fc1.bias)\n",
        "\n",
        "        z_relu = self._relu(z_fc1)\n",
        "\n",
        "        z_fc2 = self._fc(z_relu, self.fc2.weight, self.fc2.bias)\n",
        "\n",
        "        z_softmax = z_fc2.softmax(dim=1)\n",
        "\n",
        "        return z_softmax\n",
        "\n",
        "    def _forward_with_cmp(self, x):\n",
        "\n",
        "        z_conv = self._conv(x, self.conv1.weight, self.conv1.bias)\n",
        "        z_conv_target = self.conv1(x)\n",
        "        mse = F.mse_loss(z_conv, z_conv_target)\n",
        "        print(f\"Check conv. MSE: {mse}\")\n",
        "\n",
        "        z_pool = self._max_pool_kernel2(z_conv)\n",
        "        z_pool_target = F.max_pool2d(z_conv_target, 2, 2)\n",
        "        mse = F.mse_loss(z_pool, z_pool_target)\n",
        "        print(f\"Check max pool. MSE: {mse}\")\n",
        "\n",
        "        z_reshape = self._reshape(z_pool)\n",
        "        z_reshape_target = z_pool_target.view(-1, 12 * 12 * 20)\n",
        "        mse = F.mse_loss(z_reshape, z_reshape_target)\n",
        "        print(f\"Check reshape. MSE: {mse}\")\n",
        "\n",
        "        z_fc1 = self._fc(z_reshape, self.fc1.weight, self.fc1.bias)\n",
        "        z_fc1_target = self.fc1(z_reshape_target)\n",
        "        mse = F.mse_loss(z_fc1, z_fc1_target)\n",
        "        print(f\"Check fc1. MSE: {mse}\")\n",
        "\n",
        "        z_relu = self._relu(z_fc1)\n",
        "        z_relu_target = F.relu(z_fc1_target)\n",
        "        mse = F.mse_loss(z_relu, z_relu_target)\n",
        "        print(f\"Check relu. MSE: {mse}\")\n",
        "\n",
        "\n",
        "        z_fc2 = self._fc(z_relu, self.fc2.weight, self.fc2.bias)\n",
        "        z_fc2_target = self.fc2(z_relu_target)\n",
        "        mse = F.mse_loss(z_fc2, z_fc2_target)\n",
        "        print(f\"Check fc2. MSE: {mse}\")\n",
        "\n",
        "\n",
        "        z_softmax = z_fc2.softmax(dim=1)\n",
        "        z_softmax_target = z_fc2_target.softmax(dim=1)\n",
        "        mse = F.mse_loss(z_softmax, z_softmax_target)\n",
        "        print(f\"Check softmax. MSE: {mse}\")\n",
        "\n",
        "        return z_softmax\n",
        "\n",
        "\n",
        "    def _conv(self, A, W, bias):\n",
        "        n_batch = A.shape[0]\n",
        "        s_in = A.shape[2]\n",
        "\n",
        "        c_out = W.shape[0]\n",
        "        k = W.shape[2]\n",
        "\n",
        "        s_out = s_in - k + 1\n",
        "\n",
        "        z = np.zeros((n_batch, c_out, s_out, s_out))\n",
        "\n",
        "        for n in range(0, n_batch):\n",
        "            for c in range(0, c_out):\n",
        "                for m in range(0, s_out):\n",
        "                    for l in range(0, s_out):\n",
        "                        z[n, c, m, l] = self._conv_helper(A[n], W[c], m, l) + bias[c]\n",
        "\n",
        "\n",
        "        Z = torch.as_tensor(z, dtype=torch.float32)\n",
        "        Z.requires_grad_()\n",
        "\n",
        "        return Z.cuda()\n",
        "\n",
        "    def _max_pool_kernel2(self, x):\n",
        "        n_batch = x.shape[0]\n",
        "        b = x.shape[1]\n",
        "        s_conv = x.shape[2]\n",
        "\n",
        "        s_pool = s_conv // 2\n",
        "\n",
        "        z = np.zeros((n_batch, b, s_pool, s_pool))\n",
        "\n",
        "        for n in range(0, n_batch):\n",
        "            for c in range(0, b):\n",
        "                for m in range(0, s_pool):\n",
        "                    for l in range(0, s_pool):\n",
        "                        z[n, c, m, l] = torch.max(torch.tensor([x[n][c][2 * m][2 * l], x[n][c][2 * m][2 * l + 1],\n",
        "                                            x[n][c][2 * m + 1][2 * l], x[n][c][2 * m + 1][2 * l + 1]]))\n",
        "\n",
        "        Z = torch.as_tensor(z, dtype=torch.float32)\n",
        "        Z.requires_grad_()\n",
        "        return Z.cuda()\n",
        "\n",
        "    def _reshape(self, x):\n",
        "        n_batch = x.shape[0]\n",
        "        b = x.shape[1]\n",
        "        s_pool = x.shape[2]\n",
        "\n",
        "        n_reshape = b * s_pool * s_pool\n",
        "\n",
        "        z = np.zeros((n_batch, n_reshape))\n",
        "\n",
        "        for n in range(0, n_batch):\n",
        "            for c in range(0, b):\n",
        "                for m in range(0, s_pool):\n",
        "                    for l in range(0, s_pool):\n",
        "                        j = c * s_pool * s_pool + m * s_pool + l\n",
        "\n",
        "                        z[n][j] = x[n][c][m][l]\n",
        "\n",
        "        Z = torch.as_tensor(z, dtype=torch.float32)\n",
        "        Z.requires_grad_()\n",
        "\n",
        "        return Z.cuda()\n",
        "\n",
        "    def _fc(self, x, weight, bias):\n",
        "        n_batch = x.shape[0]\n",
        "        d = x.shape[1]\n",
        "\n",
        "        p = weight.shape[0]\n",
        "\n",
        "        z = np.zeros((n_batch, p))\n",
        "\n",
        "        for n in range(0, n_batch):\n",
        "            for j in range(0, p):\n",
        "                sum = 0\n",
        "                for i in range(0, d):\n",
        "                    sum += weight[j][i] * x[n][i]\n",
        "\n",
        "                z[n][j] = sum + bias[j]\n",
        "\n",
        "        Z = torch.as_tensor(z, dtype=torch.float32)\n",
        "        Z.requires_grad_()\n",
        "\n",
        "        return Z.cuda()\n",
        "\n",
        "    def _relu(self, x):\n",
        "        n_batch = x.shape[0]\n",
        "        p = x.shape[1]\n",
        "\n",
        "        z = np.zeros((n_batch, p))\n",
        "        for n in range(0, n_batch):\n",
        "            for i in range(0, p):\n",
        "                z[n, i] = max(0, x[n, i])\n",
        "\n",
        "        Z = torch.as_tensor(z, dtype=torch.float32)\n",
        "        Z.requires_grad_()\n",
        "        return Z.cuda()\n",
        "\n",
        "    def _conv_helper(self, x_n, w_c_out, m, l):\n",
        "        c_in = x_n.shape[0]\n",
        "        k = w_c_out.shape[1]\n",
        "\n",
        "        value = 0\n",
        "        for c in range(0, c_in):\n",
        "            for i in range(0, k):\n",
        "                for j in range(0, k):\n",
        "                    value += x_n[c, m + i, l + j] * w_c_out[c, i, j]\n",
        "        return value\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2x6volNtzoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNNVectorForm(nn.Module):\n",
        "\n",
        "    def __init__(self, check_with_pytorch):\n",
        "        super(CNNVectorForm, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
        "        self.fc1 = nn.Linear(12 * 12 * 20, 500)\n",
        "        self.fc2 = nn.Linear(500, 10)\n",
        "\n",
        "        self.check_with_pytorch = check_with_pytorch\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.check_with_pytorch:\n",
        "            return self._forward_with_cmp(x)\n",
        "\n",
        "        return self._forward(x)\n",
        "\n",
        "\n",
        "    def _forward(self, x):\n",
        "        z_conv = self._conv2d_vector_bonus(x, self.conv1.weight, self.conv1.bias)\n",
        "        z_pool = self._max_pool(z_conv, 2, 2)\n",
        "\n",
        "        z_reshape = z_pool.view(z_pool.shape[0], z_pool.shape[1] * z_pool.shape[2] * z_pool.shape[3])\n",
        "\n",
        "        z_fc1 = self._fc(z_reshape, self.fc1.weight, self.fc1.bias)\n",
        "\n",
        "        z_relu = z_fc1.relu()\n",
        "\n",
        "        z_fc2 = self._fc(z_relu, self.fc2.weight, self.fc2.bias)\n",
        "\n",
        "        z_softmax = z_fc2.softmax(dim=1)\n",
        "\n",
        "        return z_softmax\n",
        "\n",
        "\n",
        "    def _forward_with_cmp(self, x):\n",
        "        z_conv = self._conv2d_vector_bonus(x, self.conv1.weight, self.conv1.bias)\n",
        "        z_conv_target =  self.conv1(x)\n",
        "        mse = F.mse_loss(z_conv, z_conv_target)\n",
        "        print(f\"Check conv. MSE: {mse}\")\n",
        "\n",
        "        z_pool = self._max_pool(z_conv, 2, 2)\n",
        "        z_pool_target = F.max_pool2d(z_conv_target, 2, 2)\n",
        "        mse = F.mse_loss(z_pool, z_pool_target)\n",
        "        print(f\"Check max pool. MSE: {mse}\")\n",
        "\n",
        "        z_reshape = z_pool.view(z_pool.shape[0], z_pool.shape[1] * z_pool.shape[2] * z_pool.shape[3])\n",
        "        z_reshape_target = z_pool_target.view(-1, 12 * 12 * 20)\n",
        "        mse = F.mse_loss(z_reshape, z_reshape_target)\n",
        "        print(f\"Check reshape. MSE: {mse}\")\n",
        "\n",
        "        z_fc1 = self._fc(z_reshape, self.fc1.weight, self.fc1.bias)\n",
        "        z_fc1_target = self.fc1(z_reshape_target)\n",
        "        mse = F.mse_loss(z_fc1, z_fc1_target)\n",
        "        print(f\"Check fc1. MSE: {mse}\")\n",
        "\n",
        "        z_relu = z_fc1.relu()\n",
        "        z_relu_target = F.relu(z_fc1_target)\n",
        "        mse = F.mse_loss(z_relu, z_relu_target)\n",
        "        print(f\"Check relu. MSE: {mse}\")\n",
        "\n",
        "\n",
        "        z_fc2 = self._fc(z_relu, self.fc2.weight, self.fc2.bias)\n",
        "        z_fc2_target = self.fc2(z_relu_target)\n",
        "        mse = F.mse_loss(z_fc2, z_fc2_target)\n",
        "        print(f\"Check fc2. MSE: {mse}\")\n",
        "\n",
        "\n",
        "        z_softmax = z_fc2.softmax(dim=1)\n",
        "        z_softmax_target = z_fc2_target.softmax(dim=1)\n",
        "        mse = F.mse_loss(z_softmax, z_softmax_target)\n",
        "        print(f\"Check softmax. MSE: {mse}\")\n",
        "\n",
        "        return z_softmax\n",
        "\n",
        "\n",
        "\n",
        "    def _im2col_KK(self, x, k, s):\n",
        "        c_in = x.shape[0]\n",
        "        s_in = x.shape[1]\n",
        "\n",
        "        s_out = (s_in - k) // s + 1\n",
        "\n",
        "        h_col = k * k\n",
        "        w_col = c_in * s_out * s_out\n",
        "\n",
        "        X_col = torch.zeros(h_col, w_col, requires_grad=True).cuda()\n",
        "        i = 0\n",
        "        for c in range(0, c_in):\n",
        "            for m in range(0, s_in - k + 1, s):\n",
        "                for l in range(0, s_in - k + 1, s):\n",
        "                    x_col_i = self._mat2row(x[c, m:m + k, l:l + k])\n",
        "                    X_col[:, i] = x_col_i\n",
        "                    i += 1\n",
        "\n",
        "        return X_col\n",
        "\n",
        "    def _weight2row_kk(self, wc_conv):\n",
        "        c_out = wc_conv.shape[0]\n",
        "        k = wc_conv.shape[1]\n",
        "\n",
        "        wc_row_conv = torch.zeros(c_out, k * k, requires_grad=True).cuda()\n",
        "        for j in range(0, c_out):\n",
        "            wc_row_j = self._mat2row(wc_conv[j, :, :])\n",
        "            wc_row_conv[j, :] = wc_row_j\n",
        "\n",
        "        return wc_row_conv\n",
        "\n",
        "    def _max_pool(self, A, k, s):\n",
        "        n_batch = A.shape[0]\n",
        "        c_in = A.shape[1]\n",
        "        s_in = A.shape[2]\n",
        "\n",
        "        s_out = (s_in - k) // s + 1\n",
        "\n",
        "        Z = torch.zeros(n_batch, c_in * s_out * s_out, requires_grad=True).cuda()\n",
        "        for n in range(0, n_batch):\n",
        "            A_col_n = self._im2col_KK(A[n], k, s)\n",
        "\n",
        "            Z[n] = A_col_n.t().max(1).values\n",
        "\n",
        "        Z_pool = Z.view(n_batch, c_in, s_out, s_out)\n",
        "\n",
        "        return Z_pool\n",
        "\n",
        "    # bonus fun\n",
        "\n",
        "    def _conv2d_vector_bonus(self, A, W, bias, s=1):\n",
        "        n_btach = A.shape[0]\n",
        "        c_in = A.shape[1]\n",
        "        s_in = A.shape[2]\n",
        "\n",
        "        c_out = W.shape[0]\n",
        "        k = W.shape[2]\n",
        "\n",
        "        s_out = s_out = (s_in - k) // s + 1\n",
        "\n",
        "        B = torch.zeros(c_out, s_out, s_out, requires_grad=True).cuda()\n",
        "        for i in range(0, c_out):\n",
        "            B[i] = bias[i]\n",
        "          \n",
        "\n",
        "        Z = torch.zeros(n_btach, c_out, s_out, s_out, requires_grad=True).cuda()\n",
        "\n",
        "        for n in range(0, n_btach):\n",
        "            W_row_n = self._weight2row_bonus(W)\n",
        "            A_col_n = self._im2col_bonus(A[n], k, s)\n",
        "\n",
        "            O_mat_n = torch.mm(W_row_n, A_col_n).cuda()\n",
        "\n",
        "            O_n = O_mat_n.view((c_out, s_out, s_out))\n",
        "            Z_n = O_n + B\n",
        "\n",
        "            Z[n] = Z_n\n",
        "\n",
        "        return Z\n",
        "\n",
        "    def _weight2row_bonus(self, W):\n",
        "        c_out = W.shape[0]  # num of filters\n",
        "        c_in = W.shape[1]\n",
        "        k = W.shape[2]\n",
        "\n",
        "        W_row = torch.zeros(c_out, c_in * k * k, requires_grad=True).cuda()\n",
        "        for j in range(0, c_out):\n",
        "            W_row[j, :] = self._tensor2row(W[j, :, :, :])\n",
        "\n",
        "        return W_row\n",
        "\n",
        "    def _im2col_bonus(self, X, k, s):\n",
        "        c_in = X.shape[0]\n",
        "        s_in = X.shape[1]\n",
        "\n",
        "        s_out = (s_in - k) // s + 1\n",
        "\n",
        "        h_col = c_in * k * k\n",
        "        w_col = s_out * s_out\n",
        "\n",
        "        X_col = torch.zeros(h_col, w_col, requires_grad=True).cuda()\n",
        "\n",
        "        i = 0\n",
        "        for m in range(0, s_in - k + 1, s):\n",
        "            for l in range(0, s_in - k + 1, s):\n",
        "                X_col[:, i] = self._tensor2row(X[:, m:m + k, l:l + k])\n",
        "                i += 1\n",
        "\n",
        "        return X_col\n",
        "\n",
        "    def _tensor2row(self, R):\n",
        "        r = self._tensor2col(R).t().cuda()\n",
        "        return r\n",
        "\n",
        "    def _tensor2col(self, C):\n",
        "        N = C.shape[0]\n",
        "        M = C.shape[1]\n",
        "        L = C.shape[2]\n",
        "\n",
        "        c = torch.zeros(N * M * L, 1, requires_grad=True).cuda()\n",
        "\n",
        "        for j in range(0, N):\n",
        "            for i in range(0, M):\n",
        "                for k in range(0, L):\n",
        "                    t = j * M * L + i * L + k\n",
        "                    c[t] = C[j, i, k]\n",
        "\n",
        "        return c\n",
        "\n",
        "    def _mat2row(self, C):\n",
        "\n",
        "        N = C.shape[0]\n",
        "        M = C.shape[1]\n",
        "\n",
        "        # TODO: think about it\n",
        "        # c = C.view(N * M, 1)\n",
        "\n",
        "        c = torch.zeros(M * N, requires_grad=True).cuda()\n",
        "\n",
        "        for j in range(0, N):\n",
        "            for i in range(0, M):\n",
        "                t = j * M + i\n",
        "\n",
        "                c[t] = C[j][i]\n",
        "\n",
        "        return c\n",
        "\n",
        "    def _fc(self, A, W, bias):\n",
        "        n_batch = A.shape[0]\n",
        "\n",
        "        ones = torch.ones(n_batch, requires_grad=True).view(n_batch).tolist()\n",
        "\n",
        "        A_temp = A.t().tolist()\n",
        "        A_temp.append(ones)\n",
        "        A_new = torch.tensor(A_temp, requires_grad=True).t().cuda()\n",
        "\n",
        "        W_temp = W.t().tolist()\n",
        "        W_temp.append(bias.tolist())\n",
        "        W_new = torch.tensor(W_temp, requires_grad=True).cuda()\n",
        "\n",
        "        Z = torch.mm(A_new, W_new)\n",
        "\n",
        "        return Z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ii94NjApshvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(log_interval, model, device, train_loader, optimizer, epoch, num_iter=None):\n",
        "    model.train()\n",
        "    i = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                       100. * batch_idx / len(train_loader), loss.item()))\n",
        "            \n",
        "        i += 1\n",
        "        if num_iter is not None and i >= num_iter:\n",
        "            break\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCwKu9jrshvw",
        "colab_type": "text"
      },
      "source": [
        "#### Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7hiXbYRshvy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "use_cuda = True\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "torch.manual_seed(1)\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "batch_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4ZS0ynrshv0",
        "colab_type": "text"
      },
      "source": [
        "#### Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjVPWf0ashv1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_train_loader(batch_size):\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.1307,), (0.3081,))\n",
        "                       ])), batch_size=batch_size, shuffle=True, **kwargs)\n",
        "    \n",
        "    return train_loader\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_MNGnKCshv3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_test_loader(batch_size):\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.1307,), (0.3081,))\n",
        "        ])),\n",
        "        batch_size=batch_size, shuffle=True, **kwargs)\n",
        "    \n",
        "    return test_loader\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hIi4VtFishv4",
        "colab_type": "text"
      },
      "source": [
        "### CNN scalar form model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QX39cGqeshv5",
        "colab_type": "text"
      },
      "source": [
        "Let's check the results after each step in forwards pass for cnn implemented by scalar form. The results are compared with pytorch. To avoid weasting time, there is only 1 epoch and batch_size = 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_vKGd_pshv6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = CNNScalarForm(True).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BcaurgCshv7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "4031cf61-a4ef-461b-8f1b-b74b525a80b9"
      },
      "source": [
        "train_loader = get_train_loader(1)\n",
        "test_loader = get_test_loader(1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:01, 8474318.92it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/28881 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 127575.34it/s]           \n",
            "  0%|          | 0/1648877 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 2128446.17it/s]                           \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 49247.65it/s]            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJyn3reNshv8",
        "colab_type": "code",
        "outputId": "5c812214-be97-4f3f-932e-7d8e300dd874",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "start = time.time()\n",
        "train(1, model, device, train_loader, optimizer, 1, 1)\n",
        "end = time.time()\n",
        "print(f\"Time executing: {end - start} s\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Check conv. MSE: 4.935583056619661e-15\n",
            "Check max pool. MSE: 5.617816426623217e-15\n",
            "Check reshape. MSE: 5.617816426623217e-15\n",
            "Check fc1. MSE: 2.2707126435227154e-13\n",
            "Check relu. MSE: 1.0454752162733158e-13\n",
            "Check fc2. MSE: 5.562772668172254e-14\n",
            "Check softmax. MSE: 5.162537170386096e-16\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: -0.091373\n",
            "Time executing: 58.06030225753784 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Swt6RbucshwA",
        "colab_type": "text"
      },
      "source": [
        "### CNN vector form model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Emp4dFxcshwA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = CNNVectorForm(True).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuKYue3LshwB",
        "colab_type": "text"
      },
      "source": [
        "Compare the result after each step in forward with pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyAjxB3DshwB",
        "colab_type": "code",
        "outputId": "b96723b5-6c83-4080-c72e-1e1524118923",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "start = time.time()\n",
        "train(1, model, device, train_loader, optimizer, 1, 1)\n",
        "end = time.time()\n",
        "print(f\"Time executing: {end - start} s\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Check conv. MSE: 0.0\n",
            "Check max pool. MSE: 0.0\n",
            "Check reshape. MSE: 0.0\n",
            "Check fc1. MSE: 3.217560105747393e-15\n",
            "Check relu. MSE: 1.8387514038773704e-15\n",
            "Check fc2. MSE: 7.618905718248374e-16\n",
            "Check softmax. MSE: 8.88178432935015e-17\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: -0.095629\n",
            "Time executing: 1.162224292755127 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yCUItcishwD",
        "colab_type": "text"
      },
      "source": [
        "As we can see vector form implementation works quickly significant than scalar form (1.2 s <58.8 s) (which was expetced) for batch_size=1. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKwCPYsAshwD",
        "colab_type": "text"
      },
      "source": [
        "### Train CNN based on vector form on 20 epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Kjn79YAshwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = CNNVectorForm(False).to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImiEWSN6zEij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "train_loader = get_train_loader(batch_size)\n",
        "test_loader = get_test_loader(batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB9-GRa4shwE",
        "colab_type": "code",
        "outputId": "ff8f603b-2138-4c7d-e675-b9ba800d7d93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        }
      },
      "source": [
        "start = time.time()\n",
        "\n",
        "for epoch in range(1, 21):\n",
        "    train(10, model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)\n",
        "end = time.time()\n",
        "print(f\"Time executing: {end - start} s\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: -0.098989\n",
            "Train Epoch: 1 [640/60000 (1%)]\tLoss: -0.097323\n",
            "Train Epoch: 1 [1280/60000 (2%)]\tLoss: -0.098574\n",
            "Train Epoch: 1 [1920/60000 (3%)]\tLoss: -0.099126\n",
            "Train Epoch: 1 [2560/60000 (4%)]\tLoss: -0.099008\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-38ee17eb5b07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-7b96ca65b275>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(log_interval, model, device, train_loader, optimizer, epoch, num_iter)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-243dd8628948>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_with_cmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbmcEmSLshwG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}